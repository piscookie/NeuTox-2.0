{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80eac477",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 5/5 [01:08<00:00, 13.73s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    " \n",
    "file = 'BBB'   # NA、NT、NC\n",
    "\n",
    "file_prefixes = [\"smiles\",\"DMPNN\", \"ecfp\", \"mfbert\", \"padel\"]\n",
    "file_extension = \".csv\"\n",
    "\n",
    "file_prefix = f\"{file}_Feature_fusion/data_train\"\n",
    "file_extension = \".csv\"\n",
    "\n",
    "val_file_prefix = f\"{file}_Feature_fusion/data_valid\"\n",
    "val_file_extension = \".csv\"\n",
    "\n",
    "start_index = 0\n",
    "end_index = 4\n",
    "\n",
    "auc_scores = []\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "recall_scores = []\n",
    "mcc_scores = []\n",
    "\n",
    "\n",
    "for i in tqdm(range(start_index, end_index + 1), desc=\"Processing files\"):  # 使用 tqdm 添加进度条  \n",
    "    combined_data_train = None\n",
    "    combined_data_valid = None\n",
    "    combined_data_test = None\n",
    "    for file_feature in file_prefixes:\n",
    "        #从randomi/中获取train，valid，test    \n",
    "        \n",
    "        file_path_train = file + \"/\" +'random' + str(i) + \"/\" + file_feature + \"/\" + \"train\" + file_extension\n",
    "        data_train = pd.read_csv(file_path_train) \n",
    "                \n",
    "        file_path_valid = file + \"/\" +'random' + str(i) + \"/\" + file_feature + \"/\" + \"valid\" + file_extension\n",
    "        data_valid = pd.read_csv(file_path_valid) \n",
    "\n",
    "        file_path_test = file + \"/\" +'random' + str(i) + \"/\" + file_feature + \"/\" + \"test\" + file_extension\n",
    "        data_test = pd.read_csv(file_path_test)   \n",
    "        \n",
    "        data_train = pd.read_csv(file_path_train)     \n",
    "        data_valid = pd.read_csv(file_path_valid)   \n",
    "        data_test  = pd.read_csv(file_path_test) \n",
    "        \n",
    "        if combined_data_train is None:\n",
    "            combined_data_train = data_train\n",
    "        if combined_data_valid is None:\n",
    "            combined_data_valid = data_valid\n",
    "        if combined_data_test is None:   \n",
    "            combined_data_test  = data_test\n",
    "        else:\n",
    "            combined_data_train = pd.concat([combined_data_train, data_train], axis=1)     \n",
    "            combined_data_valid = pd.concat([combined_data_valid, data_valid], axis=1) \n",
    "            combined_data_test = pd.concat([combined_data_test, data_test], axis=1) \n",
    "    \n",
    "    folder_path = f'{file}_Feature_fusion'\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    combined_data_train.to_csv(f'{file}_Feature_fusion/data_train{i}.csv', index=False)\n",
    "    combined_data_valid.to_csv(f'{file}_Feature_fusion/data_valid{i}.csv', index=False)\n",
    "    combined_data_test.to_csv(f'{file}_Feature_fusion/data_test{i}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a732548",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据中没有空值\n",
      "该文件的行数为：10320，列数为：2828\n",
      "数据中没有空值\n",
      "该文件的行数为：10320，列数为：2828\n",
      "数据中没有空值\n",
      "该文件的行数为：10320，列数为：2828\n",
      "数据中没有空值\n",
      "该文件的行数为：10320，列数为：2828\n",
      "数据中没有空值\n",
      "该文件的行数为：10320，列数为：2828\n"
     ]
    }
   ],
   "source": [
    "# 读取CSV文件\n",
    "file_prefix = f\"{file}_Feature_fusion/data_train\"\n",
    "file_extension = \".csv\"\n",
    "\n",
    "val_file_prefix = f\"{file}_Feature_fusion/data_valid\"\n",
    "val_file_extension = \".csv\"\n",
    "\n",
    "for i in range(start_index, end_index+1):\n",
    "    \n",
    "    # 读取数据\n",
    "    file_path = file_prefix + str(i) + file_extension\n",
    "    data = pd.read_csv(file_path)\n",
    "    null_indices = None  # 初始化 null_indices 为 None\n",
    "    if data.isnull().values.any():  # 判断是否有空值\n",
    "        print(\"数据中存在空值，空值坐标为：\")\n",
    "        null_indices = np.where(data.isnull())  # 获取空值的坐标\n",
    "        if null_indices is not None:  # 再次判断 null_indices 是否有值\n",
    "            for row_index, col_index in zip(null_indices[0], null_indices[1]):\n",
    "                print(f\"行 {row_index}，列 {col_index}\")\n",
    "    else:\n",
    "        print(\"数据中没有空值\")\n",
    "    print(f\"该文件的行数为：{data.shape[0]}，列数为：{data.shape[1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "802b00cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "开始训练第0组epochs\n",
      "loss tensor(0.6611, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 1/50, Train Loss: 0.6611285209655762, Val Loss: 0.6593686938285828\n",
      "model_0训练结果更新为第0个模型\n",
      "         \n",
      "开始训练第1组epochs\n",
      "loss tensor(0.6594, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 2/50, Train Loss: 0.6593686938285828, Val Loss: 0.655245304107666\n",
      "model_0训练结果更新为第1个模型\n",
      "         \n",
      "开始训练第2组epochs\n",
      "loss tensor(0.6552, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 3/50, Train Loss: 0.655245304107666, Val Loss: 0.6498987674713135\n",
      "model_0训练结果更新为第2个模型\n",
      "         \n",
      "开始训练第3组epochs\n",
      "loss tensor(0.6499, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 4/50, Train Loss: 0.6498987674713135, Val Loss: 0.6427257061004639\n",
      "model_0训练结果更新为第3个模型\n",
      "         \n",
      "开始训练第4组epochs\n",
      "loss tensor(0.6427, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 5/50, Train Loss: 0.6427257061004639, Val Loss: 0.6337592601776123\n",
      "model_0训练结果更新为第4个模型\n",
      "         \n",
      "开始训练第5组epochs\n",
      "loss tensor(0.6338, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 6/50, Train Loss: 0.6337592601776123, Val Loss: 0.6228357553482056\n",
      "model_0训练结果更新为第5个模型\n",
      "         \n",
      "开始训练第6组epochs\n",
      "loss tensor(0.6228, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 7/50, Train Loss: 0.6228357553482056, Val Loss: 0.610396683216095\n",
      "model_0训练结果更新为第6个模型\n",
      "         \n",
      "开始训练第7组epochs\n",
      "loss tensor(0.6104, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 8/50, Train Loss: 0.610396683216095, Val Loss: 0.5957216620445251\n",
      "model_0训练结果更新为第7个模型\n",
      "         \n",
      "开始训练第8组epochs\n",
      "loss tensor(0.5957, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 9/50, Train Loss: 0.5957216620445251, Val Loss: 0.5801689624786377\n",
      "model_0训练结果更新为第8个模型\n",
      "         \n",
      "开始训练第9组epochs\n",
      "loss tensor(0.5802, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 10/50, Train Loss: 0.5801689624786377, Val Loss: 0.5640177130699158\n",
      "model_0训练结果更新为第9个模型\n",
      "         \n",
      "开始训练第10组epochs\n",
      "loss tensor(0.5640, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 11/50, Train Loss: 0.5640177130699158, Val Loss: 0.5484418272972107\n",
      "model_0训练结果更新为第10个模型\n",
      "         \n",
      "开始训练第11组epochs\n",
      "loss tensor(0.5484, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 12/50, Train Loss: 0.5484418272972107, Val Loss: 0.5340489745140076\n",
      "model_0训练结果更新为第11个模型\n",
      "         \n",
      "开始训练第12组epochs\n",
      "loss tensor(0.5340, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 13/50, Train Loss: 0.5340489745140076, Val Loss: 0.521411120891571\n",
      "model_0训练结果更新为第12个模型\n",
      "         \n",
      "开始训练第13组epochs\n",
      "loss tensor(0.5214, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 14/50, Train Loss: 0.521411120891571, Val Loss: 0.5110927224159241\n",
      "model_0训练结果更新为第13个模型\n",
      "         \n",
      "开始训练第14组epochs\n",
      "loss tensor(0.5111, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 15/50, Train Loss: 0.5110927224159241, Val Loss: 0.502979040145874\n",
      "model_0训练结果更新为第14个模型\n",
      "         \n",
      "开始训练第15组epochs\n",
      "loss tensor(0.5030, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 16/50, Train Loss: 0.502979040145874, Val Loss: 0.4966234862804413\n",
      "model_0训练结果更新为第15个模型\n",
      "         \n",
      "开始训练第16组epochs\n",
      "loss tensor(0.4966, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 17/50, Train Loss: 0.4966234862804413, Val Loss: 0.4916183650493622\n",
      "model_0训练结果更新为第16个模型\n",
      "         \n",
      "开始训练第17组epochs\n",
      "loss tensor(0.4916, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 18/50, Train Loss: 0.4916183650493622, Val Loss: 0.4875870943069458\n",
      "model_0训练结果更新为第17个模型\n",
      "         \n",
      "开始训练第18组epochs\n",
      "loss tensor(0.4876, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 19/50, Train Loss: 0.4875870943069458, Val Loss: 0.4843163788318634\n",
      "model_0训练结果更新为第18个模型\n",
      "         \n",
      "开始训练第19组epochs\n",
      "loss tensor(0.4843, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 20/50, Train Loss: 0.4843163788318634, Val Loss: 0.4816146492958069\n",
      "model_0训练结果更新为第19个模型\n",
      "         \n",
      "开始训练第20组epochs\n",
      "loss tensor(0.4816, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 21/50, Train Loss: 0.4816146492958069, Val Loss: 0.4793522357940674\n",
      "model_0训练结果更新为第20个模型\n",
      "         \n",
      "开始训练第21组epochs\n",
      "loss tensor(0.4794, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 22/50, Train Loss: 0.4793522357940674, Val Loss: 0.477438747882843\n",
      "model_0训练结果更新为第21个模型\n",
      "         \n",
      "开始训练第22组epochs\n",
      "loss tensor(0.4774, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 23/50, Train Loss: 0.477438747882843, Val Loss: 0.4757985770702362\n",
      "model_0训练结果更新为第22个模型\n",
      "         \n",
      "开始训练第23组epochs\n",
      "loss tensor(0.4758, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 24/50, Train Loss: 0.4757985770702362, Val Loss: 0.47437527775764465\n",
      "model_0训练结果更新为第23个模型\n",
      "         \n",
      "开始训练第24组epochs\n",
      "loss tensor(0.4744, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 25/50, Train Loss: 0.47437527775764465, Val Loss: 0.4731256067752838\n",
      "model_0训练结果更新为第24个模型\n",
      "         \n",
      "开始训练第25组epochs\n",
      "loss tensor(0.4731, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 26/50, Train Loss: 0.4731256067752838, Val Loss: 0.4720097482204437\n",
      "model_0训练结果更新为第25个模型\n",
      "         \n",
      "开始训练第26组epochs\n",
      "loss tensor(0.4720, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 27/50, Train Loss: 0.4720097482204437, Val Loss: 0.47100895643234253\n",
      "model_0训练结果更新为第26个模型\n",
      "         \n",
      "开始训练第27组epochs\n",
      "loss tensor(0.4710, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 28/50, Train Loss: 0.47100895643234253, Val Loss: 0.4701094329357147\n",
      "model_0训练结果更新为第27个模型\n",
      "         \n",
      "开始训练第28组epochs\n",
      "loss tensor(0.4701, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 29/50, Train Loss: 0.4701094329357147, Val Loss: 0.4693042039871216\n",
      "model_0训练结果更新为第28个模型\n",
      "         \n",
      "开始训练第29组epochs\n",
      "loss tensor(0.4693, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 30/50, Train Loss: 0.4693042039871216, Val Loss: 0.468601256608963\n",
      "model_0训练结果更新为第29个模型\n",
      "         \n",
      "开始训练第30组epochs\n",
      "loss tensor(0.4686, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 31/50, Train Loss: 0.468601256608963, Val Loss: 0.4680003523826599\n",
      "model_0训练结果更新为第30个模型\n",
      "         \n",
      "开始训练第31组epochs\n",
      "loss tensor(0.4680, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 32/50, Train Loss: 0.4680003523826599, Val Loss: 0.46749162673950195\n",
      "model_0训练结果更新为第31个模型\n",
      "         \n",
      "开始训练第32组epochs\n",
      "loss tensor(0.4675, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 33/50, Train Loss: 0.46749162673950195, Val Loss: 0.4670606851577759\n",
      "model_0训练结果更新为第32个模型\n",
      "         \n",
      "开始训练第33组epochs\n",
      "loss tensor(0.4671, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 34/50, Train Loss: 0.4670606851577759, Val Loss: 0.4666886329650879\n",
      "model_0训练结果更新为第33个模型\n",
      "         \n",
      "开始训练第34组epochs\n",
      "loss tensor(0.4667, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 35/50, Train Loss: 0.4666886329650879, Val Loss: 0.4663631021976471\n",
      "model_0训练结果更新为第34个模型\n",
      "         \n",
      "开始训练第35组epochs\n",
      "loss tensor(0.4664, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 36/50, Train Loss: 0.4663631021976471, Val Loss: 0.4660813510417938\n",
      "model_0训练结果更新为第35个模型\n",
      "         \n",
      "开始训练第36组epochs\n",
      "loss tensor(0.4661, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 37/50, Train Loss: 0.4660813510417938, Val Loss: 0.46583712100982666\n",
      "model_0训练结果更新为第36个模型\n",
      "         \n",
      "开始训练第37组epochs\n",
      "loss tensor(0.4658, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 38/50, Train Loss: 0.46583712100982666, Val Loss: 0.4656267464160919\n",
      "model_0训练结果更新为第37个模型\n",
      "         \n",
      "开始训练第38组epochs\n",
      "loss tensor(0.4656, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 39/50, Train Loss: 0.4656267464160919, Val Loss: 0.4654456675052643\n",
      "model_0训练结果更新为第38个模型\n",
      "         \n",
      "开始训练第39组epochs\n",
      "loss tensor(0.4654, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 40/50, Train Loss: 0.4654456675052643, Val Loss: 0.4652840197086334\n",
      "model_0训练结果更新为第39个模型\n",
      "         \n",
      "开始训练第40组epochs\n",
      "loss tensor(0.4653, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 41/50, Train Loss: 0.4652840197086334, Val Loss: 0.46514272689819336\n",
      "model_0训练结果更新为第40个模型\n",
      "         \n",
      "开始训练第41组epochs\n",
      "loss tensor(0.4651, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 42/50, Train Loss: 0.46514272689819336, Val Loss: 0.46504250168800354\n",
      "model_0训练结果更新为第41个模型\n",
      "         \n",
      "开始训练第42组epochs\n",
      "loss tensor(0.4650, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 43/50, Train Loss: 0.46504250168800354, Val Loss: 0.4651290476322174\n",
      "         \n",
      "开始训练第43组epochs\n",
      "loss tensor(0.4651, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 44/50, Train Loss: 0.4651290476322174, Val Loss: 0.46575960516929626\n",
      "         \n",
      "开始训练第44组epochs\n",
      "loss tensor(0.4658, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 45/50, Train Loss: 0.46575960516929626, Val Loss: 0.46662288904190063\n",
      "         \n",
      "开始训练第45组epochs\n",
      "loss tensor(0.4666, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 46/50, Train Loss: 0.46662288904190063, Val Loss: 0.4654705226421356\n",
      "         \n",
      "开始训练第46组epochs\n",
      "loss tensor(0.4655, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Train Loss: 0.4654705226421356, Val Loss: 0.4645395576953888\n",
      "model_0训练结果更新为第46个模型\n",
      "         \n",
      "开始训练第47组epochs\n",
      "loss tensor(0.4645, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 48/50, Train Loss: 0.4645395576953888, Val Loss: 0.4655628800392151\n",
      "         \n",
      "开始训练第48组epochs\n",
      "loss tensor(0.4656, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 49/50, Train Loss: 0.4655628800392151, Val Loss: 0.46471908688545227\n",
      "         \n",
      "开始训练第49组epochs\n",
      "loss tensor(0.4647, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 50/50, Train Loss: 0.46471908688545227, Val Loss: 0.4644738435745239\n",
      "model_0训练结果更新为第49个模型\n",
      "         \n",
      "第 0 组模型\n",
      "AUC: 0.9971453961492245\n",
      "ACC: 0.9817829457364341\n",
      "F1: 0.9853331252925573\n",
      "Recall: 0.9780083630168809\n",
      "MCC: 0.9614896512821223\n",
      "    \n",
      "float64\n",
      "开始训练第0组epochs\n",
      "loss tensor(0.6636, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 1/50, Train Loss: 0.6636444330215454, Val Loss: 0.6600914001464844\n",
      "model_1训练结果更新为第0个模型\n",
      "         \n",
      "开始训练第1组epochs\n",
      "loss tensor(0.6601, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 2/50, Train Loss: 0.6600914001464844, Val Loss: 0.6535824537277222\n",
      "model_1训练结果更新为第1个模型\n",
      "         \n",
      "开始训练第2组epochs\n",
      "loss tensor(0.6536, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 3/50, Train Loss: 0.6535824537277222, Val Loss: 0.6446075439453125\n",
      "model_1训练结果更新为第2个模型\n",
      "         \n",
      "开始训练第3组epochs\n",
      "loss tensor(0.6446, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 4/50, Train Loss: 0.6446075439453125, Val Loss: 0.6334139704704285\n",
      "model_1训练结果更新为第3个模型\n",
      "         \n",
      "开始训练第4组epochs\n",
      "loss tensor(0.6334, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 5/50, Train Loss: 0.6334139704704285, Val Loss: 0.6190035343170166\n",
      "model_1训练结果更新为第4个模型\n",
      "         \n",
      "开始训练第5组epochs\n",
      "loss tensor(0.6190, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 6/50, Train Loss: 0.6190035343170166, Val Loss: 0.6023283004760742\n",
      "model_1训练结果更新为第5个模型\n",
      "         \n",
      "开始训练第6组epochs\n",
      "loss tensor(0.6023, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 7/50, Train Loss: 0.6023283004760742, Val Loss: 0.5839707255363464\n",
      "model_1训练结果更新为第6个模型\n",
      "         \n",
      "开始训练第7组epochs\n",
      "loss tensor(0.5840, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 8/50, Train Loss: 0.5839707255363464, Val Loss: 0.5649392008781433\n",
      "model_1训练结果更新为第7个模型\n",
      "         \n",
      "开始训练第8组epochs\n",
      "loss tensor(0.5649, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 9/50, Train Loss: 0.5649392008781433, Val Loss: 0.5468459725379944\n",
      "model_1训练结果更新为第8个模型\n",
      "         \n",
      "开始训练第9组epochs\n",
      "loss tensor(0.5468, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 10/50, Train Loss: 0.5468459725379944, Val Loss: 0.5307953357696533\n",
      "model_1训练结果更新为第9个模型\n",
      "         \n",
      "开始训练第10组epochs\n",
      "loss tensor(0.5308, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 11/50, Train Loss: 0.5307953357696533, Val Loss: 0.5175541639328003\n",
      "model_1训练结果更新为第10个模型\n",
      "         \n",
      "开始训练第11组epochs\n",
      "loss tensor(0.5176, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 12/50, Train Loss: 0.5175541639328003, Val Loss: 0.5070827603340149\n",
      "model_1训练结果更新为第11个模型\n",
      "         \n",
      "开始训练第12组epochs\n",
      "loss tensor(0.5071, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 13/50, Train Loss: 0.5070827603340149, Val Loss: 0.49893003702163696\n",
      "model_1训练结果更新为第12个模型\n",
      "         \n",
      "开始训练第13组epochs\n",
      "loss tensor(0.4989, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 14/50, Train Loss: 0.49893003702163696, Val Loss: 0.4925732910633087\n",
      "model_1训练结果更新为第13个模型\n",
      "         \n",
      "开始训练第14组epochs\n",
      "loss tensor(0.4926, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 15/50, Train Loss: 0.4925732910633087, Val Loss: 0.4875825047492981\n",
      "model_1训练结果更新为第14个模型\n",
      "         \n",
      "开始训练第15组epochs\n",
      "loss tensor(0.4876, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 16/50, Train Loss: 0.4875825047492981, Val Loss: 0.48358768224716187\n",
      "model_1训练结果更新为第15个模型\n",
      "         \n",
      "开始训练第16组epochs\n",
      "loss tensor(0.4836, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 17/50, Train Loss: 0.48358768224716187, Val Loss: 0.48034706711769104\n",
      "model_1训练结果更新为第16个模型\n",
      "         \n",
      "开始训练第17组epochs\n",
      "loss tensor(0.4803, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 18/50, Train Loss: 0.48034706711769104, Val Loss: 0.4776897132396698\n",
      "model_1训练结果更新为第17个模型\n",
      "         \n",
      "开始训练第18组epochs\n",
      "loss tensor(0.4777, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 19/50, Train Loss: 0.4776897132396698, Val Loss: 0.4755105674266815\n",
      "model_1训练结果更新为第18个模型\n",
      "         \n",
      "开始训练第19组epochs\n",
      "loss tensor(0.4755, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 20/50, Train Loss: 0.4755105674266815, Val Loss: 0.47373008728027344\n",
      "model_1训练结果更新为第19个模型\n",
      "         \n",
      "开始训练第20组epochs\n",
      "loss tensor(0.4737, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 21/50, Train Loss: 0.47373008728027344, Val Loss: 0.4722699820995331\n",
      "model_1训练结果更新为第20个模型\n",
      "         \n",
      "开始训练第21组epochs\n",
      "loss tensor(0.4723, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 22/50, Train Loss: 0.4722699820995331, Val Loss: 0.47106078267097473\n",
      "model_1训练结果更新为第21个模型\n",
      "         \n",
      "开始训练第22组epochs\n",
      "loss tensor(0.4711, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 23/50, Train Loss: 0.47106078267097473, Val Loss: 0.47006356716156006\n",
      "model_1训练结果更新为第22个模型\n",
      "         \n",
      "开始训练第23组epochs\n",
      "loss tensor(0.4701, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 24/50, Train Loss: 0.47006356716156006, Val Loss: 0.46924301981925964\n",
      "model_1训练结果更新为第23个模型\n",
      "         \n",
      "开始训练第24组epochs\n",
      "loss tensor(0.4692, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 25/50, Train Loss: 0.46924301981925964, Val Loss: 0.4685496389865875\n",
      "model_1训练结果更新为第24个模型\n",
      "         \n",
      "开始训练第25组epochs\n",
      "loss tensor(0.4685, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 26/50, Train Loss: 0.4685496389865875, Val Loss: 0.46795371174812317\n",
      "model_1训练结果更新为第25个模型\n",
      "         \n",
      "开始训练第26组epochs\n",
      "loss tensor(0.4680, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 27/50, Train Loss: 0.46795371174812317, Val Loss: 0.46744289994239807\n",
      "model_1训练结果更新为第26个模型\n",
      "         \n",
      "开始训练第27组epochs\n",
      "loss tensor(0.4674, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 28/50, Train Loss: 0.46744289994239807, Val Loss: 0.4669981598854065\n",
      "model_1训练结果更新为第27个模型\n",
      "         \n",
      "开始训练第28组epochs\n",
      "loss tensor(0.4670, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 29/50, Train Loss: 0.4669981598854065, Val Loss: 0.46661102771759033\n",
      "model_1训练结果更新为第28个模型\n",
      "         \n",
      "开始训练第29组epochs\n",
      "loss tensor(0.4666, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 30/50, Train Loss: 0.46661102771759033, Val Loss: 0.4662782549858093\n",
      "model_1训练结果更新为第29个模型\n",
      "         \n",
      "开始训练第30组epochs\n",
      "loss tensor(0.4663, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 31/50, Train Loss: 0.4662782549858093, Val Loss: 0.46598362922668457\n",
      "model_1训练结果更新为第30个模型\n",
      "         \n",
      "开始训练第31组epochs\n",
      "loss tensor(0.4660, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 32/50, Train Loss: 0.46598362922668457, Val Loss: 0.4657087028026581\n",
      "model_1训练结果更新为第31个模型\n",
      "         \n",
      "开始训练第32组epochs\n",
      "loss tensor(0.4657, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 33/50, Train Loss: 0.4657087028026581, Val Loss: 0.46545472741127014\n",
      "model_1训练结果更新为第32个模型\n",
      "         \n",
      "开始训练第33组epochs\n",
      "loss tensor(0.4655, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 34/50, Train Loss: 0.46545472741127014, Val Loss: 0.465226411819458\n",
      "model_1训练结果更新为第33个模型\n",
      "         \n",
      "开始训练第34组epochs\n",
      "loss tensor(0.4652, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 35/50, Train Loss: 0.465226411819458, Val Loss: 0.4650181829929352\n",
      "model_1训练结果更新为第34个模型\n",
      "         \n",
      "开始训练第35组epochs\n",
      "loss tensor(0.4650, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 36/50, Train Loss: 0.4650181829929352, Val Loss: 0.46482226252555847\n",
      "model_1训练结果更新为第35个模型\n",
      "         \n",
      "开始训练第36组epochs\n",
      "loss tensor(0.4648, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 37/50, Train Loss: 0.46482226252555847, Val Loss: 0.46463537216186523\n",
      "model_1训练结果更新为第36个模型\n",
      "         \n",
      "开始训练第37组epochs\n",
      "loss tensor(0.4646, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 38/50, Train Loss: 0.46463537216186523, Val Loss: 0.464464396238327\n",
      "model_1训练结果更新为第37个模型\n",
      "         \n",
      "开始训练第38组epochs\n",
      "loss tensor(0.4645, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 39/50, Train Loss: 0.464464396238327, Val Loss: 0.46432414650917053\n",
      "model_1训练结果更新为第38个模型\n",
      "         \n",
      "开始训练第39组epochs\n",
      "loss tensor(0.4643, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 40/50, Train Loss: 0.46432414650917053, Val Loss: 0.46426627039909363\n",
      "model_1训练结果更新为第39个模型\n",
      "         \n",
      "开始训练第40组epochs\n",
      "loss tensor(0.4643, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Train Loss: 0.46426627039909363, Val Loss: 0.4644860625267029\n",
      "         \n",
      "开始训练第41组epochs\n",
      "loss tensor(0.4645, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 42/50, Train Loss: 0.4644860625267029, Val Loss: 0.4650534391403198\n",
      "         \n",
      "开始训练第42组epochs\n",
      "loss tensor(0.4651, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 43/50, Train Loss: 0.4650534391403198, Val Loss: 0.4652916193008423\n",
      "         \n",
      "开始训练第43组epochs\n",
      "loss tensor(0.4653, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 44/50, Train Loss: 0.4652916193008423, Val Loss: 0.46384409070014954\n",
      "model_1训练结果更新为第43个模型\n",
      "         \n",
      "开始训练第44组epochs\n",
      "loss tensor(0.4638, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 45/50, Train Loss: 0.46384409070014954, Val Loss: 0.4641015827655792\n",
      "         \n",
      "开始训练第45组epochs\n",
      "loss tensor(0.4641, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 46/50, Train Loss: 0.4641015827655792, Val Loss: 0.4646904170513153\n",
      "         \n",
      "开始训练第46组epochs\n",
      "loss tensor(0.4647, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 47/50, Train Loss: 0.4646904170513153, Val Loss: 0.46347078680992126\n",
      "model_1训练结果更新为第46个模型\n",
      "         \n",
      "开始训练第47组epochs\n",
      "loss tensor(0.4635, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 48/50, Train Loss: 0.46347078680992126, Val Loss: 0.46382638812065125\n",
      "         \n",
      "开始训练第48组epochs\n",
      "loss tensor(0.4638, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 49/50, Train Loss: 0.46382638812065125, Val Loss: 0.464168906211853\n",
      "         \n",
      "开始训练第49组epochs\n",
      "loss tensor(0.4642, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 50/50, Train Loss: 0.464168906211853, Val Loss: 0.4630911946296692\n",
      "model_1训练结果更新为第49个模型\n",
      "         \n",
      "第 1 组模型\n",
      "AUC: 0.9985761138885454\n",
      "ACC: 0.9893410852713178\n",
      "F1: 0.9914370231978827\n",
      "Recall: 0.9934477379095163\n",
      "MCC: 0.9773377942452907\n",
      "    \n",
      "float64\n",
      "开始训练第0组epochs\n",
      "loss tensor(0.6637, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 1/50, Train Loss: 0.6637344360351562, Val Loss: 0.6603533029556274\n",
      "model_2训练结果更新为第0个模型\n",
      "         \n",
      "开始训练第1组epochs\n",
      "loss tensor(0.6604, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 2/50, Train Loss: 0.6603533029556274, Val Loss: 0.6556859612464905\n",
      "model_2训练结果更新为第1个模型\n",
      "         \n",
      "开始训练第2组epochs\n",
      "loss tensor(0.6557, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 3/50, Train Loss: 0.6556859612464905, Val Loss: 0.6504740715026855\n",
      "model_2训练结果更新为第2个模型\n",
      "         \n",
      "开始训练第3组epochs\n",
      "loss tensor(0.6505, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 4/50, Train Loss: 0.6504740715026855, Val Loss: 0.6426954865455627\n",
      "model_2训练结果更新为第3个模型\n",
      "         \n",
      "开始训练第4组epochs\n",
      "loss tensor(0.6427, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 5/50, Train Loss: 0.6426954865455627, Val Loss: 0.6320544481277466\n",
      "model_2训练结果更新为第4个模型\n",
      "         \n",
      "开始训练第5组epochs\n",
      "loss tensor(0.6321, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 6/50, Train Loss: 0.6320544481277466, Val Loss: 0.6191251277923584\n",
      "model_2训练结果更新为第5个模型\n",
      "         \n",
      "开始训练第6组epochs\n",
      "loss tensor(0.6191, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 7/50, Train Loss: 0.6191251277923584, Val Loss: 0.6044009923934937\n",
      "model_2训练结果更新为第6个模型\n",
      "         \n",
      "开始训练第7组epochs\n",
      "loss tensor(0.6044, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 8/50, Train Loss: 0.6044009923934937, Val Loss: 0.5875380635261536\n",
      "model_2训练结果更新为第7个模型\n",
      "         \n",
      "开始训练第8组epochs\n",
      "loss tensor(0.5875, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 9/50, Train Loss: 0.5875380635261536, Val Loss: 0.569401204586029\n",
      "model_2训练结果更新为第8个模型\n",
      "         \n",
      "开始训练第9组epochs\n",
      "loss tensor(0.5694, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 10/50, Train Loss: 0.569401204586029, Val Loss: 0.5516191124916077\n",
      "model_2训练结果更新为第9个模型\n",
      "         \n",
      "开始训练第10组epochs\n",
      "loss tensor(0.5516, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 11/50, Train Loss: 0.5516191124916077, Val Loss: 0.535247266292572\n",
      "model_2训练结果更新为第10个模型\n",
      "         \n",
      "开始训练第11组epochs\n",
      "loss tensor(0.5352, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 12/50, Train Loss: 0.535247266292572, Val Loss: 0.5213778018951416\n",
      "model_2训练结果更新为第11个模型\n",
      "         \n",
      "开始训练第12组epochs\n",
      "loss tensor(0.5214, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 13/50, Train Loss: 0.5213778018951416, Val Loss: 0.5101706385612488\n",
      "model_2训练结果更新为第12个模型\n",
      "         \n",
      "开始训练第13组epochs\n",
      "loss tensor(0.5102, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 14/50, Train Loss: 0.5101706385612488, Val Loss: 0.501309871673584\n",
      "model_2训练结果更新为第13个模型\n",
      "         \n",
      "开始训练第14组epochs\n",
      "loss tensor(0.5013, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 15/50, Train Loss: 0.501309871673584, Val Loss: 0.4944387972354889\n",
      "model_2训练结果更新为第14个模型\n",
      "         \n",
      "开始训练第15组epochs\n",
      "loss tensor(0.4944, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 16/50, Train Loss: 0.4944387972354889, Val Loss: 0.4891258180141449\n",
      "model_2训练结果更新为第15个模型\n",
      "         \n",
      "开始训练第16组epochs\n",
      "loss tensor(0.4891, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 17/50, Train Loss: 0.4891258180141449, Val Loss: 0.4849826693534851\n",
      "model_2训练结果更新为第16个模型\n",
      "         \n",
      "开始训练第17组epochs\n",
      "loss tensor(0.4850, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 18/50, Train Loss: 0.4849826693534851, Val Loss: 0.4817008972167969\n",
      "model_2训练结果更新为第17个模型\n",
      "         \n",
      "开始训练第18组epochs\n",
      "loss tensor(0.4817, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 19/50, Train Loss: 0.4817008972167969, Val Loss: 0.47903481125831604\n",
      "model_2训练结果更新为第18个模型\n",
      "         \n",
      "开始训练第19组epochs\n",
      "loss tensor(0.4790, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 20/50, Train Loss: 0.47903481125831604, Val Loss: 0.4768667221069336\n",
      "model_2训练结果更新为第19个模型\n",
      "         \n",
      "开始训练第20组epochs\n",
      "loss tensor(0.4769, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 21/50, Train Loss: 0.4768667221069336, Val Loss: 0.47503840923309326\n",
      "model_2训练结果更新为第20个模型\n",
      "         \n",
      "开始训练第21组epochs\n",
      "loss tensor(0.4750, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 22/50, Train Loss: 0.47503840923309326, Val Loss: 0.473488450050354\n",
      "model_2训练结果更新为第21个模型\n",
      "         \n",
      "开始训练第22组epochs\n",
      "loss tensor(0.4735, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 23/50, Train Loss: 0.473488450050354, Val Loss: 0.4721699655056\n",
      "model_2训练结果更新为第22个模型\n",
      "         \n",
      "开始训练第23组epochs\n",
      "loss tensor(0.4722, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 24/50, Train Loss: 0.4721699655056, Val Loss: 0.47101739048957825\n",
      "model_2训练结果更新为第23个模型\n",
      "         \n",
      "开始训练第24组epochs\n",
      "loss tensor(0.4710, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 25/50, Train Loss: 0.47101739048957825, Val Loss: 0.470034658908844\n",
      "model_2训练结果更新为第24个模型\n",
      "         \n",
      "开始训练第25组epochs\n",
      "loss tensor(0.4700, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 26/50, Train Loss: 0.470034658908844, Val Loss: 0.46917879581451416\n",
      "model_2训练结果更新为第25个模型\n",
      "         \n",
      "开始训练第26组epochs\n",
      "loss tensor(0.4692, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 27/50, Train Loss: 0.46917879581451416, Val Loss: 0.46844008564949036\n",
      "model_2训练结果更新为第26个模型\n",
      "         \n",
      "开始训练第27组epochs\n",
      "loss tensor(0.4684, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 28/50, Train Loss: 0.46844008564949036, Val Loss: 0.4678034782409668\n",
      "model_2训练结果更新为第27个模型\n",
      "         \n",
      "开始训练第28组epochs\n",
      "loss tensor(0.4678, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 29/50, Train Loss: 0.4678034782409668, Val Loss: 0.46724778413772583\n",
      "model_2训练结果更新为第28个模型\n",
      "         \n",
      "开始训练第29组epochs\n",
      "loss tensor(0.4672, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 30/50, Train Loss: 0.46724778413772583, Val Loss: 0.46677547693252563\n",
      "model_2训练结果更新为第29个模型\n",
      "         \n",
      "开始训练第30组epochs\n",
      "loss tensor(0.4668, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 31/50, Train Loss: 0.46677547693252563, Val Loss: 0.4663616418838501\n",
      "model_2训练结果更新为第30个模型\n",
      "         \n",
      "开始训练第31组epochs\n",
      "loss tensor(0.4664, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 32/50, Train Loss: 0.4663616418838501, Val Loss: 0.46600279211997986\n",
      "model_2训练结果更新为第31个模型\n",
      "         \n",
      "开始训练第32组epochs\n",
      "loss tensor(0.4660, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 33/50, Train Loss: 0.46600279211997986, Val Loss: 0.46570050716400146\n",
      "model_2训练结果更新为第32个模型\n",
      "         \n",
      "开始训练第33组epochs\n",
      "loss tensor(0.4657, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 34/50, Train Loss: 0.46570050716400146, Val Loss: 0.4654398262500763\n",
      "model_2训练结果更新为第33个模型\n",
      "         \n",
      "开始训练第34组epochs\n",
      "loss tensor(0.4654, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 35/50, Train Loss: 0.4654398262500763, Val Loss: 0.465215265750885\n",
      "model_2训练结果更新为第34个模型\n",
      "         \n",
      "开始训练第35组epochs\n",
      "loss tensor(0.4652, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Train Loss: 0.465215265750885, Val Loss: 0.4650224447250366\n",
      "model_2训练结果更新为第35个模型\n",
      "         \n",
      "开始训练第36组epochs\n",
      "loss tensor(0.4650, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 37/50, Train Loss: 0.4650224447250366, Val Loss: 0.4648529291152954\n",
      "model_2训练结果更新为第36个模型\n",
      "         \n",
      "开始训练第37组epochs\n",
      "loss tensor(0.4649, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 38/50, Train Loss: 0.4648529291152954, Val Loss: 0.46469613909721375\n",
      "model_2训练结果更新为第37个模型\n",
      "         \n",
      "开始训练第38组epochs\n",
      "loss tensor(0.4647, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 39/50, Train Loss: 0.46469613909721375, Val Loss: 0.46454155445098877\n",
      "model_2训练结果更新为第38个模型\n",
      "         \n",
      "开始训练第39组epochs\n",
      "loss tensor(0.4645, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 40/50, Train Loss: 0.46454155445098877, Val Loss: 0.46439194679260254\n",
      "model_2训练结果更新为第39个模型\n",
      "         \n",
      "开始训练第40组epochs\n",
      "loss tensor(0.4644, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 41/50, Train Loss: 0.46439194679260254, Val Loss: 0.46424588561058044\n",
      "model_2训练结果更新为第40个模型\n",
      "         \n",
      "开始训练第41组epochs\n",
      "loss tensor(0.4642, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 42/50, Train Loss: 0.46424588561058044, Val Loss: 0.46411189436912537\n",
      "model_2训练结果更新为第41个模型\n",
      "         \n",
      "开始训练第42组epochs\n",
      "loss tensor(0.4641, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 43/50, Train Loss: 0.46411189436912537, Val Loss: 0.46400174498558044\n",
      "model_2训练结果更新为第42个模型\n",
      "         \n",
      "开始训练第43组epochs\n",
      "loss tensor(0.4640, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 44/50, Train Loss: 0.46400174498558044, Val Loss: 0.46396854519844055\n",
      "model_2训练结果更新为第43个模型\n",
      "         \n",
      "开始训练第44组epochs\n",
      "loss tensor(0.4640, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 45/50, Train Loss: 0.46396854519844055, Val Loss: 0.4641980528831482\n",
      "         \n",
      "开始训练第45组epochs\n",
      "loss tensor(0.4642, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 46/50, Train Loss: 0.4641980528831482, Val Loss: 0.46484795212745667\n",
      "         \n",
      "开始训练第46组epochs\n",
      "loss tensor(0.4648, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 47/50, Train Loss: 0.46484795212745667, Val Loss: 0.46503859758377075\n",
      "         \n",
      "开始训练第47组epochs\n",
      "loss tensor(0.4650, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 48/50, Train Loss: 0.46503859758377075, Val Loss: 0.46373480558395386\n",
      "model_2训练结果更新为第47个模型\n",
      "         \n",
      "开始训练第48组epochs\n",
      "loss tensor(0.4637, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 49/50, Train Loss: 0.46373480558395386, Val Loss: 0.46389496326446533\n",
      "         \n",
      "开始训练第49组epochs\n",
      "loss tensor(0.4639, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 50/50, Train Loss: 0.46389496326446533, Val Loss: 0.4645141661167145\n",
      "         \n",
      "第 2 组模型\n",
      "AUC: 0.9986260452024307\n",
      "ACC: 0.9888565891472868\n",
      "F1: 0.9910093034164646\n",
      "Recall: 0.9889218286784209\n",
      "MCC: 0.976372968649682\n",
      "    \n",
      "float64\n",
      "开始训练第0组epochs\n",
      "loss tensor(0.6631, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 1/50, Train Loss: 0.6630517244338989, Val Loss: 0.6604254841804504\n",
      "model_3训练结果更新为第0个模型\n",
      "         \n",
      "开始训练第1组epochs\n",
      "loss tensor(0.6604, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 2/50, Train Loss: 0.6604254841804504, Val Loss: 0.6551042199134827\n",
      "model_3训练结果更新为第1个模型\n",
      "         \n",
      "开始训练第2组epochs\n",
      "loss tensor(0.6551, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 3/50, Train Loss: 0.6551042199134827, Val Loss: 0.6466878056526184\n",
      "model_3训练结果更新为第2个模型\n",
      "         \n",
      "开始训练第3组epochs\n",
      "loss tensor(0.6467, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 4/50, Train Loss: 0.6466878056526184, Val Loss: 0.6358717083930969\n",
      "model_3训练结果更新为第3个模型\n",
      "         \n",
      "开始训练第4组epochs\n",
      "loss tensor(0.6359, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 5/50, Train Loss: 0.6358717083930969, Val Loss: 0.622957706451416\n",
      "model_3训练结果更新为第4个模型\n",
      "         \n",
      "开始训练第5组epochs\n",
      "loss tensor(0.6230, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 6/50, Train Loss: 0.622957706451416, Val Loss: 0.6081920266151428\n",
      "model_3训练结果更新为第5个模型\n",
      "         \n",
      "开始训练第6组epochs\n",
      "loss tensor(0.6082, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 7/50, Train Loss: 0.6081920266151428, Val Loss: 0.5910791158676147\n",
      "model_3训练结果更新为第6个模型\n",
      "         \n",
      "开始训练第7组epochs\n",
      "loss tensor(0.5911, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 8/50, Train Loss: 0.5910791158676147, Val Loss: 0.5728713870048523\n",
      "model_3训练结果更新为第7个模型\n",
      "         \n",
      "开始训练第8组epochs\n",
      "loss tensor(0.5729, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 9/50, Train Loss: 0.5728713870048523, Val Loss: 0.5546174645423889\n",
      "model_3训练结果更新为第8个模型\n",
      "         \n",
      "开始训练第9组epochs\n",
      "loss tensor(0.5546, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 10/50, Train Loss: 0.5546174645423889, Val Loss: 0.5377333760261536\n",
      "model_3训练结果更新为第9个模型\n",
      "         \n",
      "开始训练第10组epochs\n",
      "loss tensor(0.5377, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 11/50, Train Loss: 0.5377333760261536, Val Loss: 0.5233700275421143\n",
      "model_3训练结果更新为第10个模型\n",
      "         \n",
      "开始训练第11组epochs\n",
      "loss tensor(0.5234, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 12/50, Train Loss: 0.5233700275421143, Val Loss: 0.5117439031600952\n",
      "model_3训练结果更新为第11个模型\n",
      "         \n",
      "开始训练第12组epochs\n",
      "loss tensor(0.5117, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 13/50, Train Loss: 0.5117439031600952, Val Loss: 0.5027053356170654\n",
      "model_3训练结果更新为第12个模型\n",
      "         \n",
      "开始训练第13组epochs\n",
      "loss tensor(0.5027, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 14/50, Train Loss: 0.5027053356170654, Val Loss: 0.4958128333091736\n",
      "model_3训练结果更新为第13个模型\n",
      "         \n",
      "开始训练第14组epochs\n",
      "loss tensor(0.4958, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 15/50, Train Loss: 0.4958128333091736, Val Loss: 0.49049073457717896\n",
      "model_3训练结果更新为第14个模型\n",
      "         \n",
      "开始训练第15组epochs\n",
      "loss tensor(0.4905, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 16/50, Train Loss: 0.49049073457717896, Val Loss: 0.4863133132457733\n",
      "model_3训练结果更新为第15个模型\n",
      "         \n",
      "开始训练第16组epochs\n",
      "loss tensor(0.4863, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 17/50, Train Loss: 0.4863133132457733, Val Loss: 0.4829837679862976\n",
      "model_3训练结果更新为第16个模型\n",
      "         \n",
      "开始训练第17组epochs\n",
      "loss tensor(0.4830, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 18/50, Train Loss: 0.4829837679862976, Val Loss: 0.480258971452713\n",
      "model_3训练结果更新为第17个模型\n",
      "         \n",
      "开始训练第18组epochs\n",
      "loss tensor(0.4803, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 19/50, Train Loss: 0.480258971452713, Val Loss: 0.4780069589614868\n",
      "model_3训练结果更新为第18个模型\n",
      "         \n",
      "开始训练第19组epochs\n",
      "loss tensor(0.4780, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 20/50, Train Loss: 0.4780069589614868, Val Loss: 0.47614869475364685\n",
      "model_3训练结果更新为第19个模型\n",
      "         \n",
      "开始训练第20组epochs\n",
      "loss tensor(0.4761, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 21/50, Train Loss: 0.47614869475364685, Val Loss: 0.47457975149154663\n",
      "model_3训练结果更新为第20个模型\n",
      "         \n",
      "开始训练第21组epochs\n",
      "loss tensor(0.4746, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 22/50, Train Loss: 0.47457975149154663, Val Loss: 0.4732339680194855\n",
      "model_3训练结果更新为第21个模型\n",
      "         \n",
      "开始训练第22组epochs\n",
      "loss tensor(0.4732, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 23/50, Train Loss: 0.4732339680194855, Val Loss: 0.4720694124698639\n",
      "model_3训练结果更新为第22个模型\n",
      "         \n",
      "开始训练第23组epochs\n",
      "loss tensor(0.4721, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 24/50, Train Loss: 0.4720694124698639, Val Loss: 0.4710322916507721\n",
      "model_3训练结果更新为第23个模型\n",
      "         \n",
      "开始训练第24组epochs\n",
      "loss tensor(0.4710, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 25/50, Train Loss: 0.4710322916507721, Val Loss: 0.47009673714637756\n",
      "model_3训练结果更新为第24个模型\n",
      "         \n",
      "开始训练第25组epochs\n",
      "loss tensor(0.4701, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 26/50, Train Loss: 0.47009673714637756, Val Loss: 0.4692467451095581\n",
      "model_3训练结果更新为第25个模型\n",
      "         \n",
      "开始训练第26组epochs\n",
      "loss tensor(0.4692, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 27/50, Train Loss: 0.4692467451095581, Val Loss: 0.46846139430999756\n",
      "model_3训练结果更新为第26个模型\n",
      "         \n",
      "开始训练第27组epochs\n",
      "loss tensor(0.4685, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 28/50, Train Loss: 0.46846139430999756, Val Loss: 0.4677450358867645\n",
      "model_3训练结果更新为第27个模型\n",
      "         \n",
      "开始训练第28组epochs\n",
      "loss tensor(0.4677, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 29/50, Train Loss: 0.4677450358867645, Val Loss: 0.4671134948730469\n",
      "model_3训练结果更新为第28个模型\n",
      "         \n",
      "开始训练第29组epochs\n",
      "loss tensor(0.4671, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Train Loss: 0.4671134948730469, Val Loss: 0.466581791639328\n",
      "model_3训练结果更新为第29个模型\n",
      "         \n",
      "开始训练第30组epochs\n",
      "loss tensor(0.4666, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 31/50, Train Loss: 0.466581791639328, Val Loss: 0.4661474823951721\n",
      "model_3训练结果更新为第30个模型\n",
      "         \n",
      "开始训练第31组epochs\n",
      "loss tensor(0.4661, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 32/50, Train Loss: 0.4661474823951721, Val Loss: 0.4658007323741913\n",
      "model_3训练结果更新为第31个模型\n",
      "         \n",
      "开始训练第32组epochs\n",
      "loss tensor(0.4658, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 33/50, Train Loss: 0.4658007323741913, Val Loss: 0.46552300453186035\n",
      "model_3训练结果更新为第32个模型\n",
      "         \n",
      "开始训练第33组epochs\n",
      "loss tensor(0.4655, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 34/50, Train Loss: 0.46552300453186035, Val Loss: 0.4653048813343048\n",
      "model_3训练结果更新为第33个模型\n",
      "         \n",
      "开始训练第34组epochs\n",
      "loss tensor(0.4653, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 35/50, Train Loss: 0.4653048813343048, Val Loss: 0.4651276767253876\n",
      "model_3训练结果更新为第34个模型\n",
      "         \n",
      "开始训练第35组epochs\n",
      "loss tensor(0.4651, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 36/50, Train Loss: 0.4651276767253876, Val Loss: 0.46490979194641113\n",
      "model_3训练结果更新为第35个模型\n",
      "         \n",
      "开始训练第36组epochs\n",
      "loss tensor(0.4649, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 37/50, Train Loss: 0.46490979194641113, Val Loss: 0.4646466374397278\n",
      "model_3训练结果更新为第36个模型\n",
      "         \n",
      "开始训练第37组epochs\n",
      "loss tensor(0.4646, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 38/50, Train Loss: 0.4646466374397278, Val Loss: 0.464358925819397\n",
      "model_3训练结果更新为第37个模型\n",
      "         \n",
      "开始训练第38组epochs\n",
      "loss tensor(0.4644, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 39/50, Train Loss: 0.464358925819397, Val Loss: 0.4641459286212921\n",
      "model_3训练结果更新为第38个模型\n",
      "         \n",
      "开始训练第39组epochs\n",
      "loss tensor(0.4641, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 40/50, Train Loss: 0.4641459286212921, Val Loss: 0.46402379870414734\n",
      "model_3训练结果更新为第39个模型\n",
      "         \n",
      "开始训练第40组epochs\n",
      "loss tensor(0.4640, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 41/50, Train Loss: 0.46402379870414734, Val Loss: 0.46396729350090027\n",
      "model_3训练结果更新为第40个模型\n",
      "         \n",
      "开始训练第41组epochs\n",
      "loss tensor(0.4640, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 42/50, Train Loss: 0.46396729350090027, Val Loss: 0.46397194266319275\n",
      "         \n",
      "开始训练第42组epochs\n",
      "loss tensor(0.4640, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 43/50, Train Loss: 0.46397194266319275, Val Loss: 0.4639347195625305\n",
      "model_3训练结果更新为第42个模型\n",
      "         \n",
      "开始训练第43组epochs\n",
      "loss tensor(0.4639, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 44/50, Train Loss: 0.4639347195625305, Val Loss: 0.4638670086860657\n",
      "model_3训练结果更新为第43个模型\n",
      "         \n",
      "开始训练第44组epochs\n",
      "loss tensor(0.4639, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 45/50, Train Loss: 0.4638670086860657, Val Loss: 0.4635525345802307\n",
      "model_3训练结果更新为第44个模型\n",
      "         \n",
      "开始训练第45组epochs\n",
      "loss tensor(0.4636, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 46/50, Train Loss: 0.4635525345802307, Val Loss: 0.46329566836357117\n",
      "model_3训练结果更新为第45个模型\n",
      "         \n",
      "开始训练第46组epochs\n",
      "loss tensor(0.4633, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 47/50, Train Loss: 0.46329566836357117, Val Loss: 0.4632163941860199\n",
      "model_3训练结果更新为第46个模型\n",
      "         \n",
      "开始训练第47组epochs\n",
      "loss tensor(0.4632, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 48/50, Train Loss: 0.4632163941860199, Val Loss: 0.463277667760849\n",
      "         \n",
      "开始训练第48组epochs\n",
      "loss tensor(0.4633, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 49/50, Train Loss: 0.463277667760849, Val Loss: 0.4634365439414978\n",
      "         \n",
      "开始训练第49组epochs\n",
      "loss tensor(0.4634, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 50/50, Train Loss: 0.4634365439414978, Val Loss: 0.463547945022583\n",
      "         \n",
      "第 3 组模型\n",
      "AUC: 0.9985492548574235\n",
      "ACC: 0.9894379844961241\n",
      "F1: 0.9914996490680809\n",
      "Recall: 0.990958690568979\n",
      "MCC: 0.9775567072369337\n",
      "    \n",
      "float64\n",
      "开始训练第0组epochs\n",
      "loss tensor(0.6618, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 1/50, Train Loss: 0.6617870926856995, Val Loss: 0.6592004895210266\n",
      "model_4训练结果更新为第0个模型\n",
      "         \n",
      "开始训练第1组epochs\n",
      "loss tensor(0.6592, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 2/50, Train Loss: 0.6592004895210266, Val Loss: 0.6553201079368591\n",
      "model_4训练结果更新为第1个模型\n",
      "         \n",
      "开始训练第2组epochs\n",
      "loss tensor(0.6553, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 3/50, Train Loss: 0.6553201079368591, Val Loss: 0.6491841077804565\n",
      "model_4训练结果更新为第2个模型\n",
      "         \n",
      "开始训练第3组epochs\n",
      "loss tensor(0.6492, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 4/50, Train Loss: 0.6491841077804565, Val Loss: 0.6398265361785889\n",
      "model_4训练结果更新为第3个模型\n",
      "         \n",
      "开始训练第4组epochs\n",
      "loss tensor(0.6398, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 5/50, Train Loss: 0.6398265361785889, Val Loss: 0.6280698180198669\n",
      "model_4训练结果更新为第4个模型\n",
      "         \n",
      "开始训练第5组epochs\n",
      "loss tensor(0.6281, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 6/50, Train Loss: 0.6280698180198669, Val Loss: 0.6143035888671875\n",
      "model_4训练结果更新为第5个模型\n",
      "         \n",
      "开始训练第6组epochs\n",
      "loss tensor(0.6143, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 7/50, Train Loss: 0.6143035888671875, Val Loss: 0.5987345576286316\n",
      "model_4训练结果更新为第6个模型\n",
      "         \n",
      "开始训练第7组epochs\n",
      "loss tensor(0.5987, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 8/50, Train Loss: 0.5987345576286316, Val Loss: 0.5810328722000122\n",
      "model_4训练结果更新为第7个模型\n",
      "         \n",
      "开始训练第8组epochs\n",
      "loss tensor(0.5810, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 9/50, Train Loss: 0.5810328722000122, Val Loss: 0.5624263882637024\n",
      "model_4训练结果更新为第8个模型\n",
      "         \n",
      "开始训练第9组epochs\n",
      "loss tensor(0.5624, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 10/50, Train Loss: 0.5624263882637024, Val Loss: 0.5447201132774353\n",
      "model_4训练结果更新为第9个模型\n",
      "         \n",
      "开始训练第10组epochs\n",
      "loss tensor(0.5447, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 11/50, Train Loss: 0.5447201132774353, Val Loss: 0.5291795134544373\n",
      "model_4训练结果更新为第10个模型\n",
      "         \n",
      "开始训练第11组epochs\n",
      "loss tensor(0.5292, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 12/50, Train Loss: 0.5291795134544373, Val Loss: 0.5164325833320618\n",
      "model_4训练结果更新为第11个模型\n",
      "         \n",
      "开始训练第12组epochs\n",
      "loss tensor(0.5164, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 13/50, Train Loss: 0.5164325833320618, Val Loss: 0.5064811110496521\n",
      "model_4训练结果更新为第12个模型\n",
      "         \n",
      "开始训练第13组epochs\n",
      "loss tensor(0.5065, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 14/50, Train Loss: 0.5064811110496521, Val Loss: 0.49887779355049133\n",
      "model_4训练结果更新为第13个模型\n",
      "         \n",
      "开始训练第14组epochs\n",
      "loss tensor(0.4989, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 15/50, Train Loss: 0.49887779355049133, Val Loss: 0.4930248260498047\n",
      "model_4训练结果更新为第14个模型\n",
      "         \n",
      "开始训练第15组epochs\n",
      "loss tensor(0.4930, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 16/50, Train Loss: 0.4930248260498047, Val Loss: 0.48843127489089966\n",
      "model_4训练结果更新为第15个模型\n",
      "         \n",
      "开始训练第16组epochs\n",
      "loss tensor(0.4884, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 17/50, Train Loss: 0.48843127489089966, Val Loss: 0.48473629355430603\n",
      "model_4训练结果更新为第16个模型\n",
      "         \n",
      "开始训练第17组epochs\n",
      "loss tensor(0.4847, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 18/50, Train Loss: 0.48473629355430603, Val Loss: 0.48175644874572754\n",
      "model_4训练结果更新为第17个模型\n",
      "         \n",
      "开始训练第18组epochs\n",
      "loss tensor(0.4818, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 19/50, Train Loss: 0.48175644874572754, Val Loss: 0.4792914390563965\n",
      "model_4训练结果更新为第18个模型\n",
      "         \n",
      "开始训练第19组epochs\n",
      "loss tensor(0.4793, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 20/50, Train Loss: 0.4792914390563965, Val Loss: 0.47722679376602173\n",
      "model_4训练结果更新为第19个模型\n",
      "         \n",
      "开始训练第20组epochs\n",
      "loss tensor(0.4772, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 21/50, Train Loss: 0.47722679376602173, Val Loss: 0.47549131512641907\n",
      "model_4训练结果更新为第20个模型\n",
      "         \n",
      "开始训练第21组epochs\n",
      "loss tensor(0.4755, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 22/50, Train Loss: 0.47549131512641907, Val Loss: 0.4740317761898041\n",
      "model_4训练结果更新为第21个模型\n",
      "         \n",
      "开始训练第22组epochs\n",
      "loss tensor(0.4740, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 23/50, Train Loss: 0.4740317761898041, Val Loss: 0.472797155380249\n",
      "model_4训练结果更新为第22个模型\n",
      "         \n",
      "开始训练第23组epochs\n",
      "loss tensor(0.4728, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Train Loss: 0.472797155380249, Val Loss: 0.4717417061328888\n",
      "model_4训练结果更新为第23个模型\n",
      "         \n",
      "开始训练第24组epochs\n",
      "loss tensor(0.4717, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 25/50, Train Loss: 0.4717417061328888, Val Loss: 0.47082704305648804\n",
      "model_4训练结果更新为第24个模型\n",
      "         \n",
      "开始训练第25组epochs\n",
      "loss tensor(0.4708, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 26/50, Train Loss: 0.47082704305648804, Val Loss: 0.4700251519680023\n",
      "model_4训练结果更新为第25个模型\n",
      "         \n",
      "开始训练第26组epochs\n",
      "loss tensor(0.4700, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 27/50, Train Loss: 0.4700251519680023, Val Loss: 0.46931716799736023\n",
      "model_4训练结果更新为第26个模型\n",
      "         \n",
      "开始训练第27组epochs\n",
      "loss tensor(0.4693, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 28/50, Train Loss: 0.46931716799736023, Val Loss: 0.46868735551834106\n",
      "model_4训练结果更新为第27个模型\n",
      "         \n",
      "开始训练第28组epochs\n",
      "loss tensor(0.4687, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 29/50, Train Loss: 0.46868735551834106, Val Loss: 0.4681212306022644\n",
      "model_4训练结果更新为第28个模型\n",
      "         \n",
      "开始训练第29组epochs\n",
      "loss tensor(0.4681, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 30/50, Train Loss: 0.4681212306022644, Val Loss: 0.4676027297973633\n",
      "model_4训练结果更新为第29个模型\n",
      "         \n",
      "开始训练第30组epochs\n",
      "loss tensor(0.4676, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 31/50, Train Loss: 0.4676027297973633, Val Loss: 0.4671224057674408\n",
      "model_4训练结果更新为第30个模型\n",
      "         \n",
      "开始训练第31组epochs\n",
      "loss tensor(0.4671, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 32/50, Train Loss: 0.4671224057674408, Val Loss: 0.46668317914009094\n",
      "model_4训练结果更新为第31个模型\n",
      "         \n",
      "开始训练第32组epochs\n",
      "loss tensor(0.4667, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 33/50, Train Loss: 0.46668317914009094, Val Loss: 0.4662967324256897\n",
      "model_4训练结果更新为第32个模型\n",
      "         \n",
      "开始训练第33组epochs\n",
      "loss tensor(0.4663, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 34/50, Train Loss: 0.4662967324256897, Val Loss: 0.46596184372901917\n",
      "model_4训练结果更新为第33个模型\n",
      "         \n",
      "开始训练第34组epochs\n",
      "loss tensor(0.4660, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 35/50, Train Loss: 0.46596184372901917, Val Loss: 0.46566158533096313\n",
      "model_4训练结果更新为第34个模型\n",
      "         \n",
      "开始训练第35组epochs\n",
      "loss tensor(0.4657, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 36/50, Train Loss: 0.46566158533096313, Val Loss: 0.4653801918029785\n",
      "model_4训练结果更新为第35个模型\n",
      "         \n",
      "开始训练第36组epochs\n",
      "loss tensor(0.4654, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 37/50, Train Loss: 0.4653801918029785, Val Loss: 0.465114951133728\n",
      "model_4训练结果更新为第36个模型\n",
      "         \n",
      "开始训练第37组epochs\n",
      "loss tensor(0.4651, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 38/50, Train Loss: 0.465114951133728, Val Loss: 0.4648705720901489\n",
      "model_4训练结果更新为第37个模型\n",
      "         \n",
      "开始训练第38组epochs\n",
      "loss tensor(0.4649, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 39/50, Train Loss: 0.4648705720901489, Val Loss: 0.46469101309776306\n",
      "model_4训练结果更新为第38个模型\n",
      "         \n",
      "开始训练第39组epochs\n",
      "loss tensor(0.4647, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 40/50, Train Loss: 0.46469101309776306, Val Loss: 0.46479445695877075\n",
      "         \n",
      "开始训练第40组epochs\n",
      "loss tensor(0.4648, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 41/50, Train Loss: 0.46479445695877075, Val Loss: 0.46546313166618347\n",
      "         \n",
      "开始训练第41组epochs\n",
      "loss tensor(0.4655, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 42/50, Train Loss: 0.46546313166618347, Val Loss: 0.4658166170120239\n",
      "         \n",
      "开始训练第42组epochs\n",
      "loss tensor(0.4658, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 43/50, Train Loss: 0.4658166170120239, Val Loss: 0.4641116261482239\n",
      "model_4训练结果更新为第42个模型\n",
      "         \n",
      "开始训练第43组epochs\n",
      "loss tensor(0.4641, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 44/50, Train Loss: 0.4641116261482239, Val Loss: 0.46435001492500305\n",
      "         \n",
      "开始训练第44组epochs\n",
      "loss tensor(0.4644, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 45/50, Train Loss: 0.46435001492500305, Val Loss: 0.46492111682891846\n",
      "         \n",
      "开始训练第45组epochs\n",
      "loss tensor(0.4649, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 46/50, Train Loss: 0.46492111682891846, Val Loss: 0.46350806951522827\n",
      "model_4训练结果更新为第45个模型\n",
      "         \n",
      "开始训练第46组epochs\n",
      "loss tensor(0.4635, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 47/50, Train Loss: 0.46350806951522827, Val Loss: 0.4642565846443176\n",
      "         \n",
      "开始训练第47组epochs\n",
      "loss tensor(0.4643, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 48/50, Train Loss: 0.4642565846443176, Val Loss: 0.46406492590904236\n",
      "         \n",
      "开始训练第48组epochs\n",
      "loss tensor(0.4641, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 49/50, Train Loss: 0.46406492590904236, Val Loss: 0.46320611238479614\n",
      "model_4训练结果更新为第48个模型\n",
      "         \n",
      "开始训练第49组epochs\n",
      "loss tensor(0.4632, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Epoch 50/50, Train Loss: 0.46320611238479614, Val Loss: 0.464044988155365\n",
      "         \n",
      "第 4 组模型\n",
      "AUC: 0.9975688560382989\n",
      "ACC: 0.9863372093023256\n",
      "F1: 0.9890349171786298\n",
      "Recall: 0.9858914728682171\n",
      "MCC: 0.9709490682440521\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# 读取CSV文件\n",
    "for i in range(start_index, end_index+1):\n",
    "    \n",
    "    # 读取数据\n",
    "    file_path = file_prefix + str(i) + file_extension\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # 提取特征和标签\n",
    "    x_input = data.drop(['SMILES'], axis=1).values\n",
    "    y_output = data['active'].values\n",
    "    \n",
    "        # 遍历数据，将 inf 赋值为 0\n",
    "    x_input = np.nan_to_num(x_input, posinf=0, neginf=0)\n",
    "    \n",
    "#        # 检查并输出非 float64 数据的坐标\n",
    "#    for row_index, row in enumerate(x_input):\n",
    "#        for col_index, value in enumerate(row):\n",
    "#            if x_input.dtype!= np.float64:\n",
    "#                print(f\"非 float64 数据位于 ({row_index}, {col_index})，值为: {value}\")\n",
    "#    \n",
    "    #print('x_input',x_input)\n",
    "    #print('y_output',y_output)\n",
    "    \n",
    "    \n",
    "    val_x_input = data.drop(['SMILES'], axis=1).values\n",
    "    val_y_output = data['active'].values\n",
    "    \n",
    "    val_x_input = np.nan_to_num(x_input, posinf=0, neginf=0)\n",
    "    \n",
    "    # 转换为Tensor\n",
    "    print(x_input.dtype)\n",
    "#    x = torch.Tensor(x_input)\n",
    "#    y_true = torch.Tensor(y_output).view(-1, 1)    \n",
    "#    \n",
    "#    val_x = torch.Tensor(val_x_input)\n",
    "#    val_y_true = torch.Tensor(val_y_output).view(-1, 1)\n",
    "    \n",
    "#    # 查找 x_input 中的无穷值位置\n",
    "#    infinity_positions_x = np.argwhere(np.isinf(x_input))\n",
    "#    if len(infinity_positions_x) > 0:\n",
    "#        column_names = data.drop(['SMILES'], axis=1).columns\n",
    "#        infinity_column_names_x = [column_names[pos[1]] for pos in infinity_positions_x]\n",
    "#        print(\"在 x_input 中的无穷值所在列名：\", infinity_column_names_x, '         位置：',infinity_positions_x)\n",
    "#    else:\n",
    "#        print(\"在 x_input 中没有无穷值\")\n",
    "#\n",
    "#    # 查找 val_x_input 中的无穷值位置\n",
    "#    infinity_positions_val_x = np.argwhere(np.isinf(val_x_input))\n",
    "#    if len(infinity_positions_val_x) > 0:\n",
    "#        column_names = data.drop(['SMILES'], axis=1).columns\n",
    "#        infinity_column_names_val_x = [column_names[pos[1]] for pos in infinity_positions_val_x]\n",
    "#        print(\"在 val_x_input 中的无穷值所在列名：\", infinity_column_names_val_x, '        位置：',infinity_positions_x)\n",
    "#    else:\n",
    "#        print(\"在 val_x_input 中没有无穷值\")\n",
    "    \n",
    "        # 标准化特征（假设特征是数值型的）\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    x_input = scaler.fit_transform(x_input)\n",
    "    val_x_input = scaler.fit_transform(val_x_input)\n",
    "\n",
    "    # 数据放缩处理（例如，将特征值缩放到 0 到 1 之间）\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    x_input = min_max_scaler.fit_transform(x_input)\n",
    "    val_x_input = min_max_scaler.fit_transform(val_x_input)\n",
    "    \n",
    "    x = torch.Tensor(x_input)\n",
    "    y_true = torch.Tensor(y_output).view(-1, 1)    \n",
    "    \n",
    "    val_x = torch.Tensor(val_x_input)\n",
    "    val_y_true = torch.Tensor(val_y_output).view(-1, 1)\n",
    "    \n",
    "    # 数据维度\n",
    "    input_dim = x.shape[1]\n",
    "    output_dim = 1\n",
    "    hidden_dim1 = 256\n",
    "    hidden_dim2 = 128\n",
    "    hidden_dim3 = 64\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 50\n",
    "    weight_decay = 0.001\n",
    "    \n",
    "    # MLP模型定义\n",
    "    mlp = nn.Sequential(  \n",
    "        nn.Linear(input_dim, hidden_dim1),  # 第一层隐藏层  \n",
    "        nn.ReLU(),  \n",
    "        nn.Linear(hidden_dim1, hidden_dim2),  # 第二层隐藏层  \n",
    "        nn.ReLU(),  \n",
    "        nn.Linear(hidden_dim2, hidden_dim3),  # 第三层隐藏层  \n",
    "        nn.ReLU(),  \n",
    "        nn.Linear(hidden_dim3, output_dim),  # 输出层  \n",
    "        nn.Sigmoid()  \n",
    "    )  \n",
    "        \n",
    "    # 优化器和损失函数\n",
    "    optimizer = torch.optim.Adam(mlp.parameters(), lr=learning_rate,weight_decay=weight_decay)\n",
    "    loss_func =  nn.BCEWithLogitsLoss()\n",
    "    #loss_func =  nn.MSELoss()\n",
    "    best_val_loss = float('inf')\n",
    "    num_iterations_without_improvement = 0  # Initialize counter for iterations without improvement. \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print(f\"开始训练第{epoch}组epochs\")\n",
    "        prediction = mlp(x)\n",
    "        #print('prediction',prediction)\n",
    "        \n",
    "        #prediction_np = prediction.detach().numpy()\n",
    "        #df = pd.DataFrame(prediction_np)\n",
    "        #df.to_csv('prediction.csv', index=False)\n",
    "        \n",
    "        loss = loss_func(prediction, y_true)\n",
    "        print('loss',loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(optimizer)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_prediction=mlp(val_x)\n",
    "            val_loss = loss_func(val_prediction, val_y_true)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {loss.item()}, Val Loss: {val_loss.item()}\")\n",
    "        \n",
    "        #print(\"检查数据和模型输出:\")\n",
    "        #print(\"是否存在 NaN 或无穷大值在训练预测结果中:\", torch.isnan(prediction).any() or torch.isinf(prediction).any())\n",
    "        #print(\"是否存在 NaN 或无穷大值在验证预测结果中:\", torch.isnan(val_prediction).any() or torch.isinf(val_prediction).any())\n",
    "        #print(\"是否存在 NaN 或无穷大值在训练真实值中:\", torch.isnan(y_true).any() or torch.isinf(y_true).any())\n",
    "        #print(\"是否存在 NaN 或无穷大值在验证真实值中:\", torch.isnan(val_y_true).any() or torch.isinf(val_y_true).any())\n",
    "        #\n",
    "          \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss  \n",
    "            num_iterations_without_improvement = 0\n",
    "            torch.save(mlp.state_dict(), f\"./models/model_{i}.pt\")\n",
    "            #torch.save(mlp, \"model_saved/mlp1.pt\")\n",
    "            print(f'model_{i}训练结果更新为第{epoch}个模型')\n",
    "            best_epoch = epoch\n",
    "        else :\n",
    "            num_iterations_without_improvement += 1  \n",
    "            if num_iterations_without_improvement == 30:\n",
    "                print('30次迭代没有更新，结束迭代')\n",
    "                #print(f'最棒的模型是第{best_epoch}个epoch')\n",
    "                break\n",
    "        print('         ')\n",
    "        \n",
    "\n",
    "    prediction_np = prediction.data.numpy()\n",
    "        # 将 prediction 添加到 DataFrame\n",
    "    #data['prediction'] = prediction_np\n",
    "        # 将 DataFrame 保存到 CSV 文件\n",
    "    #data.to_csv('output/output_train.csv', index=True)\n",
    "    \n",
    "    # 预测并计算AUC\n",
    "    prediction_np = prediction.detach().numpy().flatten()\n",
    "    auc = roc_auc_score(y_true, prediction_np)\n",
    "    \n",
    "    threshold = 0.5\n",
    "    binary_prediction = np.where(prediction_np > threshold, 1, 0)\n",
    "    \n",
    "    acc = accuracy_score(y_true, binary_prediction)\n",
    "    f1 = f1_score(y_true, binary_prediction)\n",
    "    recall = recall_score(y_true, binary_prediction)\n",
    "    mcc = matthews_corrcoef(y_true, binary_prediction)\n",
    "    output_file = \"train_scores.csv\"\n",
    "    \n",
    "    \n",
    "    auc_scores.append(auc)\n",
    "    acc_scores.append(acc)\n",
    "    f1_scores.append(f1)\n",
    "    recall_scores.append(recall)\n",
    "    mcc_scores.append(mcc)\n",
    "    \n",
    "    print('第',i,'组模型')\n",
    "    print(\"AUC:\", auc)\n",
    "    print(\"ACC:\", acc)\n",
    "    print(\"F1:\", f1)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"MCC:\", mcc)\n",
    "    print('    ')\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "972b13e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                SMILES  active         0    1  \\\n",
      "0    CC1(C)N(OS(=O)(=O)O)C(=O)[C@H]1NC/C(=N/OCC(=O)...     0.0  0.016417  0.0   \n",
      "1    NCC[C@@H](O)C(=O)N[C@@H]1C[C@H](N)[C@H](O[C@@H...     0.0  0.004457  0.0   \n",
      "2                 CCC(=O)C(=O)c1ccc(OCC(=O)O)c(Cl)c1Cl     1.0  0.054507  0.0   \n",
      "3    CCCCC(=O)O[C@H]1CC[C@H]2[C@@H]3CCc4cc(O)ccc4[C...     0.0  0.321503  0.0   \n",
      "4                                          CC(N)C(=O)O     1.0  0.000000  0.0   \n",
      "..                                                 ...     ...       ...  ...   \n",
      "124  COc1ccc2c3c1O[C@@H]1C(=O)CC[C@]4(O)[C@H](C2)N(...     1.0  0.355105  0.0   \n",
      "125            Nc1nc(NCCc2ccc(O)cc2)nc2nc(c3ccco3)nn12     0.0  0.067366  0.0   \n",
      "126  CCCCc1nc(C)c(CC(=S)N(C)C)c(=O)n1Cc1ccc(c2ccccc...     0.0  0.125567  0.0   \n",
      "127  CC(=O)[C@H]1CC[C@H]2[C@@H]3CC=C4C[C@@H](OC(=O)...     1.0  0.338337  0.0   \n",
      "128            C[C@H](C(=O)O)c1ccc(N2Cc3ccccc3C2=O)cc1     1.0  0.175397  0.0   \n",
      "\n",
      "            2         3         4         5         6         7  ...  \\\n",
      "0    0.045795  0.115336  0.005305  0.364727  0.086362  0.068767  ...   \n",
      "1    0.008947  0.110185  0.000000  0.466615  0.319754  0.231110  ...   \n",
      "2    0.068592  0.120811  0.000942  0.479436  0.144606  0.003635  ...   \n",
      "3    0.065637  0.040700  0.000000  0.800448  0.222785  0.000000  ...   \n",
      "4    0.048480  0.251501  0.000000  0.200593  0.084869  0.126119  ...   \n",
      "..        ...       ...       ...       ...       ...       ...  ...   \n",
      "124  0.106816  0.008518  0.000000  0.908130  0.237880  0.000382  ...   \n",
      "125  0.180557  0.046768  0.009535  0.715946  0.141853  0.025424  ...   \n",
      "126  0.143121  0.044024  0.000000  0.687210  0.181224  0.016603  ...   \n",
      "127  0.015487  0.055174  0.000000  0.767600  0.199580  0.005456  ...   \n",
      "128  0.174315  0.032424  0.000000  0.734396  0.272352  0.006127  ...   \n",
      "\n",
      "          724       725       726       727       728       729       730  \\\n",
      "0    0.000009  0.347826  0.531589  0.352069  0.199962  0.913287  0.413221   \n",
      "1    0.000018  0.501057  0.000000  0.258220  0.300227  0.925408  0.479324   \n",
      "2    0.000011  0.121784  0.000000  0.383742  0.139017  0.902098  0.177336   \n",
      "3    0.000018  0.070245  0.531589  0.224899  0.202798  0.961772  0.080825   \n",
      "4    0.000003  0.095592  0.000000  0.250824  0.039773  0.817716  0.069344   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "124  0.000014  0.089070  0.531589  0.262248  0.183403  0.983217  0.145129   \n",
      "125  0.000013  0.192331  0.675017  0.308605  0.195614  0.965035  0.271769   \n",
      "126  0.000016  0.184934  0.531589  0.273929  0.276711  0.947786  0.265507   \n",
      "127  0.000017  0.121784  0.531589  0.230941  0.230926  0.949184  0.126938   \n",
      "128  0.000010  0.086972  0.531589  0.285903  0.161739  0.949650  0.108151   \n",
      "\n",
      "          731       732       733  \n",
      "0    0.304935  0.012517  0.277041  \n",
      "1    0.527824  0.032442  0.026460  \n",
      "2    0.191240  0.004636  0.506358  \n",
      "3    0.121959  0.010436  0.725827  \n",
      "4    0.069762  0.000181  0.228721  \n",
      "..        ...       ...       ...  \n",
      "124  0.169042  0.005651  0.382176  \n",
      "125  0.083291  0.010729  0.466100  \n",
      "126  0.038923  0.026928  0.689844  \n",
      "127  0.191540  0.015919  0.648991  \n",
      "128  0.110484  0.006006  0.514853  \n",
      "\n",
      "[129 rows x 2828 columns]\n",
      "43te_x_input.shape torch.Size([129, 2827])\n",
      "AUC_1: 0.9713358572201191\n",
      "Accuracy_1: 0.9224806201550387\n",
      "f1_1: 0.9397590361445783\n",
      "recall_1: 0.9069767441860465\n",
      "mcc_1: 0.8357448101873574\n",
      "             \n",
      "             \n",
      "                                                SMILES  active         0    1  \\\n",
      "0    CC(=O)OCC(=O)[C@@]1(O)CCC2C3C[C@H](Cl)C4=CC(=O...       1  0.247310  0.0   \n",
      "1    CC(=O)Oc1ccc2C[C@@H]3N(C)CCC[C@]45c2c1O[C@H]4[...       1  0.325588  0.0   \n",
      "2    CCOC(=O)O[C@@]1(C(=O)COC(=O)CC)CC[C@@H]2[C@H]3...       1  0.214170  0.0   \n",
      "3    CC1=C[C@@H](O)CC(=O)Cc2nc(co2)C(=O)N2CCC=C2C(=...       0  0.117618  0.0   \n",
      "4                     [Cl-].NC12CC3CC(CC(C3)C1)C2.[H+]       1  0.395250  0.0   \n",
      "..                                                 ...     ...       ...  ...   \n",
      "124         O=C1CC[C@H](C(=O)N[C@H]2C[C@H]2c2ccccc2)N1       1  0.144312  0.0   \n",
      "125  CC/C=C(/C(=O)N[C@H]1C(=O)N2C(=C(CS[C@@H]12)COC...       0  0.022651  0.0   \n",
      "126           Cc1ccccc1n1c(nc2ccccc2c1=O)/C=C\\c1ccccn1       1  0.250727  0.0   \n",
      "127          COc1ccc(S(N)(=O)=O)cc1C(=O)NC[C@H]1CCCN1C       1  0.047567  0.0   \n",
      "128                                           CCC(C)CC       1  0.000000  0.0   \n",
      "\n",
      "            2         3         4         5         6         7  ...  \\\n",
      "0    0.166582  0.015899  0.014829  0.904652  0.380245  0.053498  ...   \n",
      "1    0.242704  0.012651  0.006969  0.974171  0.362371  0.101155  ...   \n",
      "2    0.133795  0.033294  0.014216  0.886883  0.333937  0.068484  ...   \n",
      "3    0.213190  0.008890  0.042282  0.779197  0.296308  0.168274  ...   \n",
      "4    0.062941  0.000000  0.006409  1.033463  0.449980  0.006611  ...   \n",
      "..        ...       ...       ...       ...       ...       ...  ...   \n",
      "124  0.204037  0.014731  0.018649  0.908388  0.415260  0.234887  ...   \n",
      "125  0.272400  0.033983  0.029098  0.667369  0.248946  0.414252  ...   \n",
      "126  0.382662  0.000000  0.022893  1.163080  0.273962  0.109600  ...   \n",
      "127  0.230493  0.020017  0.027715  0.766731  0.274390  0.166651  ...   \n",
      "128  0.000000  0.030556  0.000000  0.529553  0.194085  0.014520  ...   \n",
      "\n",
      "        724.1     725.1     726.1     727.1     728.1     729.1     730.1  \\\n",
      "0    0.848531  0.200000  0.983195  0.000057  0.000023  0.175855  0.461331   \n",
      "1    0.597617  0.173700  0.982938  0.000037  0.000016  0.117074  0.461331   \n",
      "2    0.778813  0.097980  0.971702  0.000058  0.000020  0.209068  0.461331   \n",
      "3    0.582753  0.177700  0.977149  0.000056  0.000018  0.250090  0.585802   \n",
      "4    0.614604  0.014300  0.983738  0.000006  0.000006  0.046815  0.000000   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "124  0.516928  0.015640  0.973947  0.000015  0.000010  0.104714  0.790881   \n",
      "125  0.628996  0.002162  0.935921  0.000038  0.000015  0.416517  0.461331   \n",
      "126  0.402383  0.306500  0.989297  0.000028  0.000013  0.081972  0.000000   \n",
      "127  0.672526  0.166600  0.986276  0.000077  0.000042  0.198093  0.461331   \n",
      "128  0.548071  0.000000  0.924713  0.333333  0.666667  0.000000  0.000000   \n",
      "\n",
      "        731.1     732.1     733.1  \n",
      "0    0.123651  0.891703  0.013701  \n",
      "1    0.109203  0.952838  0.010505  \n",
      "2    0.096024  0.889956  0.021078  \n",
      "3    0.107896  0.868122  0.029065  \n",
      "4    0.040806  0.968559  0.000773  \n",
      "..        ...       ...       ...  \n",
      "124  0.107336  0.894323  0.004224  \n",
      "125  0.184469  0.873362  0.016100  \n",
      "126  0.133732  0.937991  0.009950  \n",
      "127  0.123315  0.855022  0.006847  \n",
      "128  0.000000  0.680349  0.000193  \n",
      "\n",
      "[129 rows x 2828 columns]\n",
      "43te_x_input.shape torch.Size([129, 2827])\n",
      "AUC_2: 0.9442724458204335\n",
      "Accuracy_2: 0.8372093023255814\n",
      "f1_2: 0.8813559322033899\n",
      "recall_2: 0.8210526315789474\n",
      "mcc_2: 0.6439486109298651\n",
      "             \n",
      "             \n",
      "                                                SMILES  active         0  \\\n",
      "0                CSCC1CC2C(N(C1)CCC)Cc1c[nH]c3cccc2c13       1  0.608879   \n",
      "1    CC(C)(C)NC[C@H](O)COc1cccc2c1C[C@H](O)[C@@H](O)C2       1  0.230217   \n",
      "2               O=C1NCCC[C@@H]1N1C(=O)c2ccccc2S1(=O)=O       1  0.270651   \n",
      "3    CN(C)[C@@H]1C(=C(C(=O)N)C(=O)C2(O)C(=C3C(=O)c4...       0  0.289481   \n",
      "4     Cc1ccc(S[C@H](C)C(=O)NCc2nc(c3cccc(Br)c3)no2)cc1       0  0.250287   \n",
      "..                                                 ...     ...       ...   \n",
      "124                            c1cn(CCCCC)c(C)c(O)c1=O       1  0.216858   \n",
      "125  CC(C)C[C@H]1C(=O)N2CCC[C@H]2[C@]2(O)O[C@](NC(=...       0  0.436634   \n",
      "126                         COC(=O)C(c1ccccc1)C1CCCCN1       1  0.272044   \n",
      "127  CC(C)(C)NC(=O)[C@@H]1CC[C@@H]2[C@@H]3CC[C@@H]4...       1  0.661877   \n",
      "128       CC(=O)c1ccc2Sc3ccccc3N(CCCN3CCC(CCO)CC3)c2c1       1  0.523730   \n",
      "\n",
      "            1         2         3         4         5         6         7  \\\n",
      "0    0.003255  0.349338  0.011499  0.023581  0.967009  0.262428  0.025054   \n",
      "1    0.000000  0.159544  0.020533  0.014019  0.654396  0.293492  0.101985   \n",
      "2    0.000000  0.367613  0.005964  0.238872  0.735135  0.219627  0.098127   \n",
      "3    0.000000  0.306752  0.007909  0.168150  0.668741  0.195849  0.187608   \n",
      "4    0.000000  0.355296  0.011086  0.101817  0.740460  0.159570  0.099126   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "124  0.003140  0.278561  0.020144  0.070010  0.683784  0.084193  0.052417   \n",
      "125  0.000000  0.292693  0.005272  0.109070  0.765758  0.278407  0.140583   \n",
      "126  0.000000  0.254486  0.009163  0.044494  0.758141  0.265195  0.057040   \n",
      "127  0.000000  0.224443  0.008613  0.091762  0.954386  0.376540  0.047668   \n",
      "128  0.002262  0.358165  0.009735  0.106553  0.893845  0.197417  0.027112   \n",
      "\n",
      "     ...     724.1     725.1     726.1     727.1     728.1     729.1  \\\n",
      "0    ...  0.990816  0.000023  0.000015  0.073455  0.531589  0.070899   \n",
      "1    ...  0.992735  0.000012  0.000007  0.135791  0.000000  0.062003   \n",
      "2    ...  0.987981  0.000012  0.000009  0.152328  0.531589  0.165115   \n",
      "3    ...  0.979735  0.000026  0.000012  0.310522  0.000000  0.123969   \n",
      "4    ...  0.975422  0.000015  0.000008  0.154631  0.531589  0.193959   \n",
      "..   ...       ...       ...       ...       ...       ...       ...   \n",
      "124  ...  0.997857  0.000005  0.000005  0.067175  0.000000  0.061398   \n",
      "125  ...  0.974229  0.000036  0.000012  0.195857  0.761250  0.121054   \n",
      "126  ...  0.765527  0.428571  0.441123  0.063513  0.000000  0.068287   \n",
      "127  ...  0.981950  0.000024  0.000013  0.096437  0.531589  0.046824   \n",
      "128  ...  0.994270  0.000017  0.000007  0.114466  0.000000  0.086343   \n",
      "\n",
      "        730.1     731.1     732.1     733.1  \n",
      "0    0.977156  0.080824  0.017820  0.708682  \n",
      "1    0.925874  0.116309  0.022043  0.601674  \n",
      "2    0.949650  0.172961  0.011476  0.574093  \n",
      "3    0.940793  0.222146  0.042533  0.585286  \n",
      "4    0.944056  0.175021  0.038196  0.737029  \n",
      "..        ...       ...       ...       ...  \n",
      "124  0.907692  0.072077  0.006117  0.673989  \n",
      "125  0.964103  0.280258  0.112601  0.693201  \n",
      "126  0.940326  0.071133  0.009355  0.648361  \n",
      "127  0.949650  0.094764  0.032610  0.723152  \n",
      "128  0.963170  0.129871  0.045563  0.720188  \n",
      "\n",
      "[129 rows x 2828 columns]\n",
      "43te_x_input.shape torch.Size([129, 2827])\n",
      "AUC_3: 0.9727366255144033\n",
      "Accuracy_3: 0.7751937984496124\n",
      "f1_3: 0.8481675392670157\n",
      "recall_3: 1.0\n",
      "mcc_3: 0.5398863516771588\n",
      "             \n",
      "             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                SMILES  active         0    1  \\\n",
      "0    COc1cccc(OC)c1C(=O)N[C@@H]1C(=O)N2[C@@H](C(=O)...       0  0.000000  0.0   \n",
      "1    CCC[C@H]1O[C@H]2C[C@H]3[C@@H]4C[C@H](F)C5=CC(=...       1  0.311698  0.0   \n",
      "2    O=S(=O)(c1ccc(Cl)cc1)[C@@H]1[C@H](CO)[C@H]1c1c...       1  0.110724  0.0   \n",
      "3    COc1cccc2C(=O)c3c(O)c4C[C@@](O)(C[C@@H](O[C@H]...       0  0.050428  0.0   \n",
      "4                              Brc1cccc(Br)c1N=C1NCCN1       1  0.086606  0.0   \n",
      "..                                                 ...     ...       ...  ...   \n",
      "124  COc1cc(C2c3cc4c(cc3C(OC3OC5COC(C)OC5C(O)C3O)C3...       0  0.065901  0.0   \n",
      "125         COc1cc(N)c(Cl)cc1C(=O)NC1CCN(Cc2ccccc2)CC1       1  0.137272  0.0   \n",
      "126                                     FC(Br)C(F)(F)F       1  0.234055  0.0   \n",
      "127   CC(C)n1cc2CC3C(CC(CN3C)C(=O)NC3CCCCC3)c3cccc1c23       1  0.300840  0.0   \n",
      "128  c1(ccc(c(c1)Cl)Cl)CC(N1C(CC2(CC1)NC(NC2=O)=O)C...       0  0.229174  0.0   \n",
      "\n",
      "            2         3         4         5         6         7  ...  \\\n",
      "0    0.162881  0.023196  0.000000  0.425829  0.095087  0.143356  ...   \n",
      "1    0.109866  0.032660  0.000000  0.522417  0.201714  0.024089  ...   \n",
      "2    0.215511  0.000000  0.000000  0.626607  0.202260  0.044431  ...   \n",
      "3    0.211619  0.008925  0.002009  0.581207  0.099068  0.076263  ...   \n",
      "4    0.220673  0.033400  0.009946  0.534119  0.079339  0.064274  ...   \n",
      "..        ...       ...       ...       ...       ...       ...  ...   \n",
      "124  0.139764  0.018242  0.000000  0.478651  0.187466  0.094438  ...   \n",
      "125  0.195361  0.006792  0.000397  0.668445  0.162561  0.013019  ...   \n",
      "126  0.046333  0.000000  0.000000  0.297303  0.193335  0.000000  ...   \n",
      "127  0.197885  0.000000  0.000000  0.703884  0.248905  0.032530  ...   \n",
      "128  0.154919  0.000723  0.017075  0.626543  0.215658  0.021013  ...   \n",
      "\n",
      "        724.1     725.1    726.1     727.1     728.1     729.1     730.1  \\\n",
      "0    0.331806  0.683214  0.02938  0.965314  0.000015  0.000012  0.197011   \n",
      "1    0.390176  0.817940  0.31190  0.982371  0.000054  0.000028  0.177536   \n",
      "2    0.364053  0.628608  0.02183  0.969622  0.000013  0.000013  0.094731   \n",
      "3    0.339163  0.620526  0.37860  0.982734  0.000090  0.000040  0.317331   \n",
      "4    0.000000  0.449319  0.10350  0.987992  0.000006  0.000008  0.054982   \n",
      "..        ...       ...      ...       ...       ...       ...       ...   \n",
      "124  0.350881  0.545024  0.16820  0.971687  0.000051  0.000025  0.242754   \n",
      "125  0.329780  0.532325  0.17260  0.982723  0.000022  0.000018  0.102038   \n",
      "126  0.000000  0.844493  0.05475  0.992311  0.000001  0.000004  0.000000   \n",
      "127  0.224053  0.503579  0.25930  0.985197  0.000033  0.000024  0.056265   \n",
      "128  0.411894  0.630801  0.21380  0.983079  0.000020  0.000015  0.123415   \n",
      "\n",
      "        731.1     732.1     733.1  \n",
      "0    0.531589  0.265777  0.931935  \n",
      "1    0.675017  0.234320  0.944522  \n",
      "2    0.911328  0.287745  0.938462  \n",
      "3    0.000000  0.253104  0.952914  \n",
      "4    0.531589  0.443229  0.938462  \n",
      "..        ...       ...       ...  \n",
      "124  0.675017  0.255645  0.972494  \n",
      "125  0.000000  0.240045  0.945921  \n",
      "126  0.000000  0.723384  0.818648  \n",
      "127  0.531589  0.197652  0.972494  \n",
      "128  0.675017  0.265873  0.951049  \n",
      "\n",
      "[129 rows x 2828 columns]\n",
      "43te_x_input.shape torch.Size([129, 2827])\n",
      "AUC_4: 0.913337250293772\n",
      "Accuracy_4: 0.8837209302325582\n",
      "f1_4: 0.9214659685863874\n",
      "recall_4: 0.9565217391304348\n",
      "mcc_4: 0.705748318726327\n",
      "             \n",
      "             \n",
      "Average AUC: 0.950421±0.024230\n",
      "Average Accuracy: 0.854651±0.054917\n",
      "Average F1: 0.897687±0.035547\n",
      "Average Recall: 0.921138±0.066500\n",
      "Average MCC: 0.681332±0.107056\n"
     ]
    }
   ],
   "source": [
    "te_file_prefix = f\"{file}_Feature_fusion/data_test\"\n",
    "te_file_extension = \".csv\"\n",
    "\n",
    "import os \n",
    "\n",
    "avg_auc = 0.0  \n",
    "avg_acc = 0.0  \n",
    "avg_f1 = 0.0  \n",
    "avg_recall = 0.0  \n",
    "avg_mcc = 0.0  \n",
    "\n",
    "\n",
    "#te_file_paths = [te_file_prefix + str(i) + te_file_extension for i in range(start_index, end_index+1)]  \n",
    "results = pd.DataFrame(columns=['AUC', 'Accuracy', 'F1', 'Recall', 'MCC'])   \n",
    "    \n",
    "#for i,te_file_path in enumerate(te_file_paths):  \n",
    "for i in range(start_index, end_index): \n",
    "    te_file_path = te_file_prefix + str(i) + te_file_extension\n",
    "    data_test = pd.read_csv(te_file_path)  \n",
    "    if file == 'BBB':\n",
    "        data_test = data_test.head(129)  \n",
    "\n",
    "    print(data_test)\n",
    "      \n",
    "    te_x_input = data_test.drop(['SMILES'], axis=1).values  \n",
    "    #print('1te_x_input.shape',te_x_input.shape)\n",
    "    \n",
    "    te_y_true = data_test['active'].values  \n",
    "    te_x_input = te_x_input.astype(np.float64)\n",
    "    #print('2te_x_input.shape',te_x_input.shape)\n",
    "    \n",
    "    te_x_input = np.nan_to_num(te_x_input, posinf=0, neginf=0)\n",
    "    #print('3te_x_input',te_x_input.shape)    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    te_x_input = scaler.fit_transform(te_x_input)\n",
    "\n",
    "#    # 数据放缩处理（例如，将特征值缩放到 0 到 1 间）\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    te_x_input = min_max_scaler.fit_transform(te_x_input)\n",
    "    te_x_input = torch.Tensor(te_x_input)\n",
    "    print('43te_x_input.shape',te_x_input.shape)\n",
    "    mlp.load_state_dict(torch.load(f\"models/model_{i+1}.pt\")) \n",
    "    \n",
    "    \n",
    "#    print(\"Length of te_prediction:\", len(te_prediction))\n",
    "#    print(\"Length of data_test:\", len(data_test))\n",
    "#    print(\"Length of data index:\", len(data.index))\n",
    "    \n",
    "    with torch.no_grad():    \n",
    "        \n",
    "       # print(\"47  te_x_input  te_x_input\",te_x_input)\n",
    "    \n",
    "        #print('5te_x_input.shape',te_x_input.shape)\n",
    "        te_prediction = mlp(te_x_input)  \n",
    "        \n",
    "        ############################################################\n",
    "        te_prediction = te_prediction.numpy()\n",
    "        data = pd.DataFrame(te_prediction)\n",
    "        data.to_csv(f'output1/test_prediction{i+1}.csv', mode='a', index=False)\n",
    "        ############################################################\n",
    "        \n",
    "        #print('te_y_true',len(te_y_true))\n",
    "        #print('te_prediction',len(te_prediction))\n",
    "        #print('te_y_true',te_y_true)\n",
    "        #print('te_prediction',te_prediction)\n",
    "        #print('检查 te_y_true 是否包含 NaN',np.isnan(te_y_true).any())  # 检查 te_y_true 是否包含 NaN\n",
    "        #print('检查 te_y_true 是否包含无穷值',np.isinf(te_y_true).any())  # 检查 te_y_true 是否包含无穷值\n",
    "        #print('检查 te_prediction 是否包含 NaN',np.isnan(te_prediction).any())  # 检查 te_prediction 是否包含 NaN\n",
    "        #print('检查 te_prediction 是否包含无穷值',np.isinf(te_prediction).any())  # 检查 te_prediction 是否包含无穷值\n",
    "        #\n",
    "        auc = roc_auc_score(te_y_true, te_prediction)\n",
    "        #print(auc)\n",
    "        \n",
    "        #print('54  te_predictionte_prediction',te_prediction)    \n",
    "        #te_prediction = te_prediction.numpy()      \n",
    "        data_test[f'te_prediction_{i+1}'] = te_prediction \n",
    "        \n",
    "        auc = roc_auc_score(te_y_true, te_prediction)\n",
    "        #print(auc)\n",
    "        \n",
    "        #data_test.to_csv(f'output1/te_prediction{i+1}.csv', mode='a', index=True)\n",
    "        #print('te_prediction  ',te_prediction)\n",
    "        \n",
    "        auc = roc_auc_score(te_y_true, te_prediction)  \n",
    "        print(f'AUC_{i+1}: {auc}')\n",
    "        \n",
    "        te_prediction_binary = np.where(te_prediction > 0.5, 1, 0)  \n",
    "        acc = accuracy_score(te_y_true, te_prediction_binary)  \n",
    "        print(f'Accuracy_{i+1}: {acc}')\n",
    "        f1 = f1_score(te_y_true, te_prediction_binary)\n",
    "        recall = recall_score(te_y_true, te_prediction_binary)\n",
    "        mcc = matthews_corrcoef(te_y_true, te_prediction_binary)\n",
    "        print(f'f1_{i+1}: {f1}')\n",
    "        print(f'recall_{i+1}: {recall}')\n",
    "        print(f'mcc_{i+1}: {mcc}')\n",
    "        print('             ')\n",
    "        print('             ')\n",
    "        \n",
    "        avg_auc += auc  \n",
    "        avg_acc += acc  \n",
    "        avg_f1 += f1  \n",
    "        avg_recall += recall  \n",
    "        avg_mcc += mcc\n",
    "        \n",
    "        results = results.append({'AUC': auc, 'Accuracy': acc, 'F1': f1, 'Recall': recall, 'MCC': mcc}, ignore_index=True) \n",
    "results.to_csv('测试集预测_results.csv', index=False)\n",
    "\n",
    "avg_auc /= len(range(start_index, end_index)) \n",
    "avg_acc /= len(range(start_index, end_index)) \n",
    "avg_f1 /= len(range(start_index, end_index))  \n",
    "avg_recall /= len(range(start_index, end_index))\n",
    "avg_mcc /= len(range(start_index, end_index))\n",
    "\n",
    "auc_te_values = results['AUC'].values\n",
    "accuracy_te_values = results['Accuracy'].values\n",
    "f1_te_values = results['F1'].values\n",
    "recall_te_values = results['Recall'].values\n",
    "mcc_te_values = results['MCC'].values\n",
    "\n",
    "std_auc_te = np.std(auc_te_values)\n",
    "std_acc_te = np.std(accuracy_te_values)\n",
    "std_f1_te = np.std(f1_te_values)\n",
    "std_recall_te = np.std(recall_te_values)\n",
    "std_mcc_te = np.std(mcc_te_values)\n",
    "\n",
    "print(f'Average AUC: {avg_auc:.6f}±{std_auc_te:.6f}')\n",
    "print(f'Average Accuracy: {avg_acc:.6f}±{std_acc_te:.6f}')\n",
    "print(f'Average F1: {avg_f1:.6f}±{std_f1_te:.6f}')\n",
    "print(f'Average Recall: {avg_recall:.6f}±{std_recall_te:.6f}')\n",
    "print(f'Average MCC: {avg_mcc:.6f}±{std_mcc_te:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df67982a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3509277829.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_406944/3509277829.py\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    Average AUC: 0.850873±0.116283\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "hidden_dim1 = 512\n",
    "hidden_dim2 = 256\n",
    "hidden_dim3 = 64\n",
    "learning_rate = 0.1\n",
    "num_epochs = 100\n",
    "weight_decay = 0.001\n",
    "\n",
    "Average AUC: 0.850873±0.116283\n",
    "Average Accuracy: 0.658915±0.239119\n",
    "Average F1: 0.647554±0.376343\n",
    "Average Recall: 0.730789±0.422637\n",
    "Average MCC: 0.383128±0.270336\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    hidden_dim1 = 512\n",
    "    hidden_dim2 = 256\n",
    "    hidden_dim3 = 64\n",
    "learning_rate = 0.1\n",
    "num_epochs = 100\n",
    "weight_decay = 0.01\n",
    "\n",
    "Average AUC: 0.914110±0.023841\n",
    "Average Accuracy: 0.451550±0.226031\n",
    "Average F1: 0.224390±0.388655\n",
    "Average Recall: 0.250000±0.433013\n",
    "Average MCC: 0.148338±0.256930\n",
    "\n",
    "    \n",
    "\n",
    "    hidden_dim1 = 512\n",
    "    hidden_dim2 = 256\n",
    "    hidden_dim3 = 64\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "weight_decay = 0.01\n",
    "\n",
    "Average AUC: 0.943448±0.020126\n",
    "Average Accuracy: 0.796512±0.098723\n",
    "Average F1: 0.831558±0.094451\n",
    "Average Recall: 0.774691±0.173856\n",
    "Average MCC: 0.624705±0.130822\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    output_dim = 1\n",
    "    hidden_dim1 = 512\n",
    "    hidden_dim2 = 256\n",
    "    hidden_dim3 = 64\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 100\n",
    "    weight_decay = 0.01\n",
    "    \n",
    "Average AUC: 0.725601±0.064932\n",
    "Average Accuracy: 0.598296±0.056470\n",
    "Average F1: 0.666462±0.026149\n",
    "Average Recall: 0.785408±0.030126\n",
    "Average MCC: 0.353964±0.151104"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95c28f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea29637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.8cu111",
   "language": "python",
   "name": "pytorch1.8cu111"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
